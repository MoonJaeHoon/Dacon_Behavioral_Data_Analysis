{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-1번_Generating_CountVectorizer_Features_Bytime2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_9LhJ7SnQhF8"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoonJaeHoon/Dacon_Behavioral_Data_Analysis/blob/master/2_1%EB%B2%88_Generating_CountVectorizer_Features_Bytime2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1HUBrsTiOXw",
        "colab_type": "code",
        "outputId": "7df22867-2c91-4639-b557-19f2147b90ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIF5I3jmiVci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "print( '변경 전 기본 경로 :' )\n",
        "print(  os.getcwd() )\n",
        "os.chdir('./drive/My Drive/데이콘_게임데이터분석')\n",
        "print( '변경 후 파일 경로 :' )\n",
        "print(  os.getcwd()  )\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tqdm import tqdm_notebook              # 진행바\n",
        "from sklearn.metrics import roc_auc_score   # AUC 스코어 계산\n",
        "from sklearn.model_selection import KFold   # K-fold CV    \n",
        "#from bayes_opt import BayesianOptimization  # 베이지안 최적화 라이브러리  \n",
        "from functools import partial               # 함수 변수 고정\n",
        "import lightgbm as lgb                      # LightGBM 라이브러리\n",
        "import warnings                             \n",
        "warnings.filterwarnings(\"ignore\")           # 경고 문구 미표시\n",
        "%time\n",
        "train = pd.read_csv('./train.csv')\n",
        "\n",
        "#%time\n",
        "#test = pd.read_pickle('./test.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayo2uTrUQg_O",
        "colab_type": "code",
        "outputId": "3e2e9c0c-d602-4ac7-e21e-1259b9892fd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "Ability = train.loc[train['event']=='Ability',:].loc[train['time']<2,:]\n",
        "import re\n",
        "def SUB(x):\n",
        "    result = re.sub(' ','',str(x)) + ','\n",
        "    #result = re.sub('[[0-9]+]',    '',     result)\n",
        "    result = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\\g<1>\\g<2>\", result)\n",
        "    #result = re.sub('Location:.+',    'Location:',     result)\n",
        "    return result\n",
        "\n",
        "Ability['event_contents'] = Ability.apply(lambda x: SUB(x['event_contents']), axis=1)\n",
        "Ability['event_contents'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()-Attack;Location:(),                                              457150\n",
              "()-TrainSCV,                                                        350376\n",
              "()-MorphDrone,                                                      287254\n",
              "()-TrainProbe,                                                      258765\n",
              "()-TrainMarine,                                                     134801\n",
              "                                                                     ...  \n",
              "()-GravitonBeam;Target:ExtendingBridgeNEWide10Out[];Location:(),         1\n",
              "()-KD8Charge;Target:SwarmHost[];Location:(),                             1\n",
              "()-ScanMove;Target:SpineCrawler[];Location:(),                           1\n",
              "()-BuildAssimilator;Target:StarportReactor[];Location:(),                1\n",
              "()-Move;Target:StarportFlying[];Location:(),                             1\n",
              "Name: event_contents, Length: 1232, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8nRNgjVP6wl",
        "colab_type": "text"
      },
      "source": [
        "## 1. CountVevtorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ihIsoI8mnsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Ability_CountVectorizer_bytime(t):\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import re\n",
        "    def SUB(x):\n",
        "        result = re.sub(' ','',str(x)) + ','\n",
        "        #result = re.sub('[[0-9]+]',    '',     result)\n",
        "        result = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\\g<1>\\g<2>\", result)\n",
        "        #result = re.sub('Location:.+',    'Location:',     result)\n",
        "        return result\n",
        "\n",
        "    train = pd.read_csv('train.csv')\n",
        "    Ability2 = train.loc[train['event']=='Ability',:].loc[train['time']<t,:]\n",
        "\n",
        "    Ability2['event_contents'] = Ability2.apply(lambda x: SUB(x['event_contents']), axis=1)\n",
        "    #Ability2['event_contents'].value_counts()\n",
        "    game_id = train.game_id.unique().tolist()\n",
        "    columns = ['text0','text1','winner']\n",
        "    mytrain = np.zeros(len(game_id)*len(columns))\n",
        "    mytrain = mytrain.reshape(len(game_id),len(columns))\n",
        "    mytrain = pd.DataFrame(mytrain, columns=columns)\n",
        "    mytrain.index = game_id\n",
        "    mytrain.winner = train.loc[train['player']==0,:].groupby(    ['game_id'] )['winner'].max()\n",
        "    mytrain.loc[:,'text0'] = Ability2.loc[Ability2['player']==0,:].loc[Ability2['event']=='Ability',:].groupby(['game_id']).event_contents.sum()\n",
        "    mytrain.loc[:,'text1'] = Ability2.loc[Ability2['player']==1,:].loc[Ability2['event']=='Ability',:].groupby(['game_id']).event_contents.sum()\n",
        "    del train\n",
        "    del Ability2\n",
        "    mytrain = mytrain.fillna('')\n",
        "\n",
        "    test = pd.read_csv('test.csv')\n",
        "    Ability2 = test.loc[test['event']=='Ability',:].loc[test['time']<t,:]\n",
        "\n",
        "    Ability2['event_contents'] = Ability2.apply(lambda x: SUB(x['event_contents']), axis=1)\n",
        "    #Ability2['event_contents'].value_counts()\n",
        "    game_id = test.game_id.unique().tolist()\n",
        "    columns = ['text0','text1']\n",
        "    mytest = np.zeros(len(game_id)*len(columns))\n",
        "    mytest = mytest.reshape(len(game_id),len(columns))\n",
        "    mytest = pd.DataFrame(mytest, columns=columns)\n",
        "    mytest.index = game_id\n",
        "\n",
        "    mytest.loc[:,'text0'] = Ability2.loc[Ability2['player']==0,:].loc[Ability2['event']=='Ability',:].groupby(['game_id']).event_contents.sum()\n",
        "    mytest.loc[:,'text1'] = Ability2.loc[Ability2['player']==1,:].loc[Ability2['event']=='Ability',:].groupby(['game_id']).event_contents.sum()\n",
        "    del test\n",
        "    del Ability2\n",
        "    mytest = mytest.fillna('')\n",
        "\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import pickle\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from nltk.corpus import stopwords\n",
        "    from sklearn.feature_extraction.text import TfidfTransformer\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    def tokenizer(text):\n",
        "        return text.split(',')\n",
        "\n",
        "    ########### 사용할 모수들 ###################\n",
        "    min_df = 1\n",
        "    ngram_range = (1,1)\n",
        "    seed = 42\n",
        "\n",
        "    ######################## 데이터로부터 단어가방 생성 ####################\n",
        "    vectorizer0 = CountVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
        "    revised_reviews0 = [' '.join(review.split(',')) for review in mytrain.text0]\n",
        "    vector_reviews0 = vectorizer0.fit_transform(revised_reviews0)\n",
        "    print(vector_reviews0.shape)\n",
        "\n",
        "    vectorizer1 = CountVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
        "    revised_reviews1 = [' '.join(review.split(',')) for review in mytrain.text1]\n",
        "    vector_reviews1 = vectorizer1.fit_transform(revised_reviews1)\n",
        "    print(vector_reviews1.shape)\n",
        "\n",
        "    player0 = pd.DataFrame(   vector_reviews0.toarray()*1, columns = vectorizer0.get_feature_names()  )\n",
        "    player0 = player0.add_prefix('player0_')\n",
        "    player1 = pd.DataFrame(   vector_reviews1.toarray()*1, columns = vectorizer1.get_feature_names()  )\n",
        "    player1 = player1.add_prefix('player1_')\n",
        "    X = pd.concat([player0,player1],axis=1)\n",
        "    y = mytrain.winner\n",
        "    print(X.shape)\n",
        "    del vectorizer0, vectorizer1, revised_reviews0, revised_reviews1, vector_reviews0, vector_reviews1\n",
        "    del player0, player1\n",
        "\n",
        "\n",
        "    ######################## Test data ####################\n",
        "    vectorizer0 = CountVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
        "    revised_reviews0 = [' '.join(review.split(',')) for review in mytest.text0]\n",
        "    vector_reviews0 = vectorizer0.fit_transform(revised_reviews0)\n",
        "    print(vector_reviews0.shape)\n",
        "\n",
        "    vectorizer1 = CountVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
        "    revised_reviews1 = [' '.join(review.split(',')) for review in mytest.text1]\n",
        "    vector_reviews1 = vectorizer1.fit_transform(revised_reviews1)\n",
        "    print(vector_reviews1.shape)\n",
        "\n",
        "    player0 = pd.DataFrame(   vector_reviews0.toarray()*1, columns = vectorizer0.get_feature_names()  )\n",
        "    player0 = player0.add_prefix('player0_')\n",
        "    player1 = pd.DataFrame(   vector_reviews1.toarray()*1, columns = vectorizer1.get_feature_names()  )\n",
        "    player1 = player1.add_prefix('player1_')\n",
        "\n",
        "    del vectorizer0, vectorizer1, revised_reviews0, revised_reviews1, vector_reviews0, vector_reviews1\n",
        "\n",
        "    X_test = pd.concat([player0,player1],axis=1)\n",
        "    print(X_test.shape)\n",
        "\n",
        "    del player0, player1\n",
        "\n",
        "    ################ Train 이랑 Test에서 겹치는 column들만 남기기 ###########\n",
        "    print(len(X.columns))\n",
        "    print(len(X_test.columns))\n",
        "    print(  len(    set(X.columns) & set(X_test.columns)   ) )\n",
        "\n",
        "    use_col = list(    set(X.columns) & set(X_test.columns)   )\n",
        "\n",
        "    X = X.loc[:,use_col]\n",
        "    X_test = X_test.loc[:,use_col]\n",
        "\n",
        "    X = X.add_prefix('Time_'+str(t) +'_')\n",
        "    X_test = X_test.add_prefix('Time_'+str(t) +'_' )\n",
        "    return X, X_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaNJqqVjg8vL",
        "colab_type": "text"
      },
      "source": [
        "## time < 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2CeZLzAP-M_",
        "colab_type": "code",
        "outputId": "ceb5cbca-645f-4437-c333-7450e8172982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "t=2\n",
        "X, X_test = Ability_CountVectorizer_bytime(t)\n",
        "\n",
        "X.to_pickle('train_Ability'+str(t)+'.pkl')\n",
        "X_test.to_pickle('test_Ability'+str(t)+'.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38872, 134)\n",
            "(38872, 130)\n",
            "(38872, 264)\n",
            "(16787, 113)\n",
            "(16787, 112)\n",
            "(16787, 225)\n",
            "264\n",
            "225\n",
            "211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMik0S80gJdF",
        "colab_type": "text"
      },
      "source": [
        "## time < 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkVARDntgK8r",
        "colab_type": "code",
        "outputId": "1e7d5ca2-e2d2-46ae-d6d8-b0ade6f9ca75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "t=4\n",
        "X, X_test = Ability_CountVectorizer_bytime(t)\n",
        "\n",
        "X.to_pickle('train_Ability'+str(t)+'.pkl')\n",
        "X_test.to_pickle('test_Ability'+str(t)+'.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38872, 264)\n",
            "(38872, 267)\n",
            "(38872, 531)\n",
            "(16787, 239)\n",
            "(16787, 235)\n",
            "(16787, 474)\n",
            "531\n",
            "474\n",
            "455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgkVXzyQhAqq",
        "colab_type": "text"
      },
      "source": [
        "## time < 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCdTWA7vgU43",
        "colab_type": "code",
        "outputId": "07959097-ecbb-4ed9-8a81-1a1943e3e374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "t=6\n",
        "X, X_test = Ability_CountVectorizer_bytime(t)\n",
        "\n",
        "X.to_pickle('train_Ability'+str(t)+'.pkl')\n",
        "X_test.to_pickle('test_Ability'+str(t)+'.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38872, 392)\n",
            "(38872, 397)\n",
            "(38872, 789)\n",
            "(16787, 357)\n",
            "(16787, 367)\n",
            "(16787, 724)\n",
            "789\n",
            "724\n",
            "697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiXz9_i9hF-V",
        "colab_type": "text"
      },
      "source": [
        "## time < 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd_sTx23hIOP",
        "colab_type": "code",
        "outputId": "440275c5-f8c3-4edd-a2ad-8de9f270c56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "t=8\n",
        "X, X_test = Ability_CountVectorizer_bytime(t)\n",
        "\n",
        "X.to_pickle('train_Ability'+str(t)+'.pkl')\n",
        "X_test.to_pickle('test_Ability'+str(t)+'.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38872, 470)\n",
            "(38872, 467)\n",
            "(38872, 937)\n",
            "(16787, 436)\n",
            "(16787, 441)\n",
            "(16787, 877)\n",
            "937\n",
            "877\n",
            "857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzbZ5o3VhpCq",
        "colab_type": "text"
      },
      "source": [
        "## time<10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64yKI1t_hqFP",
        "colab_type": "code",
        "outputId": "3e27da28-1ca9-4c6b-b331-087ddc99b6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "t=10\n",
        "X, X_test = Ability_CountVectorizer_bytime(t)\n",
        "\n",
        "X.to_pickle('train_Ability'+str(t)+'.pkl')\n",
        "X_test.to_pickle('test_Ability'+str(t)+'.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38872, 503)\n",
            "(38872, 497)\n",
            "(38872, 1000)\n",
            "(16787, 475)\n",
            "(16787, 473)\n",
            "(16787, 948)\n",
            "1000\n",
            "948\n",
            "931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac5I6D18RPET",
        "colab_type": "text"
      },
      "source": [
        "## 모델링 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqw-MMTbfp1O",
        "colab_type": "code",
        "outputId": "bf66a5d9-dec1-45e8-f3fe-5013a5e981a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_Ability2 = pd.read_pickle('train_Ability2.pkl')\n",
        "train_Ability4 = pd.read_pickle('train_Ability4.pkl')\n",
        "train_Ability6 = pd.read_pickle('train_Ability6.pkl')\n",
        "train_Ability8 = pd.read_pickle('train_Ability8.pkl')\n",
        "train_Ability10 = pd.read_pickle('train_Ability10.pkl')\n",
        "train_Ability = pd.read_pickle('train_Ability.pkl')\n",
        "X = pd.concat([train_Ability2,train_Ability4,train_Ability6,train_Ability8,train_Ability10,train_Ability],axis=1)\n",
        "del train_Ability2,train_Ability4,train_Ability6,train_Ability8,train_Ability10,train_Ability\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38872, 4087)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncu-umoocTf",
        "colab_type": "code",
        "outputId": "69c2f056-4fc4-4c11-8483-28bb3860c820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_Ability2 = pd.read_pickle('test_Ability2.pkl')\n",
        "test_Ability4 = pd.read_pickle('test_Ability4.pkl')\n",
        "test_Ability6 = pd.read_pickle('test_Ability6.pkl')\n",
        "test_Ability8 = pd.read_pickle('test_Ability8.pkl')\n",
        "test_Ability10 = pd.read_pickle('test_Ability10.pkl')\n",
        "test_Ability = pd.read_pickle('test_Ability.pkl')\n",
        "X_test = pd.concat([test_Ability2,test_Ability4,test_Ability6,test_Ability8,test_Ability10,test_Ability],axis=1)\n",
        "del test_Ability2,test_Ability4,test_Ability6,test_Ability8,test_Ability10,test_Ability\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16787, 4087)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUPydfyJy8B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "y = train.loc[train['player']==0,:].groupby(    ['game_id'] )['winner'].max()\n",
        "del train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU4CC7EvwWkT",
        "colab_type": "code",
        "outputId": "f980cafd-124e-40c1-80df-3fae045c5bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "seed = 42\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "#################### 모델링 시작 #######################\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y,   stratify=y, random_state=seed)\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "#model_bern = BernoulliNB().fit(X_train, y_train)\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#MNB = MultinomialNB(alpha=1).fit(X_train,y_train)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=5000, random_state=seed,n_jobs=-1).fit(X_train, y_train)\n",
        "print('랜포 학습완료')\n",
        "from lightgbm import LGBMClassifier\n",
        "lgbm = LGBMClassifier(random_state=seed).fit(X_train,y_train)\n",
        "print('LGBM 학습완료')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "랜포 학습완료\n",
            "LGBM 학습완료\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKohTPrXb8kI",
        "colab_type": "code",
        "outputId": "843babef-3ff5-4d3e-b469-ab21359f08c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "## 랜포 #  ngram (1,1) : 0.6889\n",
        "## 2씩 time구간 나눠서 : 0.6868\n",
        "## n_estimator 5000 : 0.6887\n",
        "y_pred = rf.predict_proba(X_valid)[:,1]\n",
        "print(rf)\n",
        "print(\"테스트 정확도: {:.4f}\".format(roc_auc_score(y_valid, y_pred)))\n",
        "\n",
        "## LGBM #  ngram (1,1) : 0.6824\n",
        "## 2씩 time구간 나눠서 : 0.6834\n",
        "\n",
        "y_pred = lgbm.predict_proba(X_valid)[:,1]\n",
        "print(lgbm)\n",
        "print(\"테스트 정확도: {:.4f}\".format(roc_auc_score(y_valid, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=5000,\n",
            "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
            "                       warm_start=False)\n",
            "테스트 정확도: 0.6887\n",
            "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
            "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
            "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
            "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
            "테스트 정확도: 0.6834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9LhJ7SnQhF8",
        "colab_type": "text"
      },
      "source": [
        "## 2. TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPbrCTLtQio-",
        "colab_type": "code",
        "outputId": "842767f5-9fb9-4e95-ee34-67a03daf05d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "def tokenizer(text):\n",
        "    return text.split(',')\n",
        "\n",
        "########### 사용할 모수들 ###################\n",
        "min_df = 1\n",
        "ngram_range = (1,1)\n",
        "seed = 42\n",
        "\n",
        "######################## 데이터로부터 단어가방 생성 ####################\n",
        "vectorizer0 = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
        "revised_reviews0 = [' '.join(review.split(',')) for review in mytrain.text0]\n",
        "vector_reviews0 = vectorizer0.fit_transform(revised_reviews0)\n",
        "print(vector_reviews0.shape)\n",
        "\n",
        "vectorizer1 = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
        "revised_reviews1 = [' '.join(review.split(',')) for review in mytrain.text1]\n",
        "vector_reviews1 = vectorizer1.fit_transform(revised_reviews1)\n",
        "print(vector_reviews1.shape)\n",
        "\n",
        "player0 = pd.DataFrame(   vector_reviews0.toarray()*1, columns = vectorizer0.get_feature_names()  )\n",
        "player0 = player0.add_prefix('player0_')\n",
        "player1 = pd.DataFrame(   vector_reviews1.toarray()*1, columns = vectorizer1.get_feature_names()  )\n",
        "player1 = player1.add_prefix('player1_')\n",
        "X = pd.concat([player0,player1],axis=1)\n",
        "y = mytrain.winner\n",
        "print(X.shape)\n",
        "del vectorizer0, vectorizer1, revised_reviews0, revised_reviews1, vector_reviews0, vector_reviews1\n",
        "del player0, player1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38872, 504)\n",
            "(38872, 500)\n",
            "(38872, 1004)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnIGE5Nw3tfR",
        "colab_type": "code",
        "outputId": "dbcf777b-4741-45c8-92a5-d11951c5e71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#del X_train, X_valid, y_train, y_valid\n",
        "########### 사용할 모수들 ###################\n",
        "min_df = 1\n",
        "ngram_range = (1,1)\n",
        "seed = 42\n",
        "\n",
        "######################## 데이터로부터 단어가방 생성 ####################\n",
        "vectorizer0 = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
        "revised_reviews0 = [' '.join(review.split(',')) for review in mytest.text0]\n",
        "vector_reviews0 = vectorizer0.fit_transform(revised_reviews0)\n",
        "print(vector_reviews0.shape)\n",
        "\n",
        "vectorizer1 = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
        "revised_reviews1 = [' '.join(review.split(',')) for review in mytest.text1]\n",
        "vector_reviews1 = vectorizer1.fit_transform(revised_reviews1)\n",
        "print(vector_reviews1.shape)\n",
        "\n",
        "player0 = pd.DataFrame(   vector_reviews0.toarray()*1, columns = vectorizer0.get_feature_names()  )\n",
        "player0 = player0.add_prefix('player0_')\n",
        "player1 = pd.DataFrame(   vector_reviews1.toarray()*1, columns = vectorizer1.get_feature_names()  )\n",
        "player1 = player1.add_prefix('player1_')\n",
        "\n",
        "del vectorizer0, vectorizer1, revised_reviews0, revised_reviews1, vector_reviews0, vector_reviews1\n",
        "\n",
        "X_test = pd.concat([player0,player1],axis=1)\n",
        "print(X_test.shape)\n",
        "\n",
        "del player0, player1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16787, 476)\n",
            "(16787, 475)\n",
            "(16787, 951)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE2q9eEI32p5",
        "colab_type": "code",
        "outputId": "14704197-79ef-40db-d973-f722a2ba45ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(len(X.columns))\n",
        "print(len(X_test.columns))\n",
        "print(  len(    set(X.columns) & set(X_test.columns)   ) )\n",
        "\n",
        "use_col = list(    set(X.columns) & set(X_test.columns)   )\n",
        "\n",
        "X = X.loc[:,use_col]\n",
        "X_test = X_test.loc[:,use_col]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1004\n",
            "951\n",
            "936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjM8n2l039Sq",
        "colab_type": "code",
        "outputId": "8f91f812-ea7e-440c-e92a-5f3cd594ac37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "#################### 모델링 시작 #######################\n",
        "train_Ability = pd.read_pickle('train_Ability.pkl')\n",
        "CONCAT = pd.concat([train_Ability,X],axis=1)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(CONCAT, y,   stratify=y, random_state=seed)\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "#model_bern = BernoulliNB().fit(X_train, y_train)\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#MNB = MultinomialNB(alpha=1).fit(X_train,y_train)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=1000, random_state=seed,verbose=1,n_jobs=-1).fit(X_train, y_train)\n",
        "print('랜포 학습완료')\n",
        "from lightgbm import LGBMClassifier\n",
        "lgbm = LGBMClassifier(random_state=seed).fit(X_train,y_train)\n",
        "print('LGBM 학습완료')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   26.8s\n",
            "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "랜포 학습완료\n",
            "LGBM 학습완료\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFQz7IfoZsSC",
        "colab_type": "code",
        "outputId": "befed5a1-ad04-4cf5-bccb-b358708f6c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "## 랜포 #  ngram (1,1) : 0.6661\n",
        "y_pred = rf.predict_proba(X_valid)[:,1]\n",
        "print(rf)\n",
        "print(\"테스트 정확도: {:.4f}\".format(roc_auc_score(y_valid, y_pred)))\n",
        "\n",
        "## LGBM #  ngram (1,1) : 0.6547\n",
        "y_pred = lgbm.predict_proba(X_valid)[:,1]\n",
        "print(lgbm)\n",
        "print(\"테스트 정확도: {:.4f}\".format(roc_auc_score(y_valid, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    2.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
            "                       n_jobs=-1, oob_score=False, random_state=42, verbose=1,\n",
            "                       warm_start=False)\n",
            "테스트 정확도: 0.6852\n",
            "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
            "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
            "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
            "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
            "테스트 정확도: 0.6794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3RfS_ib0qH-",
        "colab_type": "text"
      },
      "source": [
        "## 생성한 데이터 (Train & Test) pickle로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAMC00p-z6bY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X.to_pickle('train_Ability.pkl')\n",
        "#X_test.to_pickle('test_Ability.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac48tz8-gl_E",
        "colab_type": "code",
        "outputId": "d5cbe54a-add6-4cbf-aeda-07440cd090df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "pred = rf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission = pd.read_csv('sample_submission.csv', index_col=0)\n",
        "submission['winner'] = submission['winner'] + pred\n",
        "submission.to_csv('제출/전처리17_단어임베딩만으로.csv', encoding='utf8')\n",
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>winner</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>game_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38872</th>\n",
              "      <td>0.467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38873</th>\n",
              "      <td>0.479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38874</th>\n",
              "      <td>0.482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38875</th>\n",
              "      <td>0.323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38876</th>\n",
              "      <td>0.704</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         winner\n",
              "game_id        \n",
              "38872     0.467\n",
              "38873     0.479\n",
              "38874     0.482\n",
              "38875     0.323\n",
              "38876     0.704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW5X0jA1utPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}